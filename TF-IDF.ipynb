{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalbooks = pd.read_csv('finalbook.csv')\n",
    "ratings = pd.read_csv('finalratings.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_k(r,k):\n",
    "    '''Discounted Cumulative Gain(DCG)\n",
    "    r: True Ratings in Predicted Rank Order(1st element is top recommendation)\n",
    "    k: Number of results to consider \n",
    "    '''\n",
    "    \n",
    "    r = np.asfarray(r)[:k]\n",
    "    dcg = np.sum(2**r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return dcg\n",
    "\n",
    "def ndcg_k(r,k):\n",
    "    \"Normalized Discounted Cumulative Gain(NDCG)\"\n",
    "    \n",
    "    dcg_max = dcg_k(sorted(r, reverse=True), k)\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return dcg_k(r,k) / dcg_max\n",
    "\n",
    "def mean_ndcg(rs):\n",
    "    '''Mean NDCG for all users\n",
    "    rs: Iterator/For each user: True ratings in Predicted Rank orde\n",
    "    '''\n",
    "    \n",
    "    mean = np.mean([ndcg_k(r, len(r)) for r in rs])\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y,h):\n",
    "    '''Root Mean Squared Error(RMSE)\n",
    "    y: real y\n",
    "    h: predicted y\n",
    "    '''\n",
    "    \n",
    "    a=y-h\n",
    "    return np.sqrt(sum(a**2)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the tail\n",
    "tailcomp = ratings.groupby(by='newbookid', as_index=False).agg({'rating': pd.Series.count}).sort_values(by='rating', ascending=False)\n",
    "tot=sum(tailcomp['rating'])\n",
    "tailcomp['popshare'] = [x/tot for x in tailcomp['rating']]\n",
    "tailcomp['popshare'] = tailcomp['popshare'].cumsum()\n",
    "tailcomp['category'] = ['Head' if x<0.95 else \"Tail\" for x in tailcomp['popshare']]\n",
    "tail = tailcomp.loc[tailcomp.popshare>=0.95]\n",
    "tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(message):\n",
    "    '''Get the normalized list of words from a message string.\n",
    "    This function should split a message into words, normalize them and return the resulting list.\n",
    "    For splitting, you should split on spaces. For normalization, you should convert everything to lowercase.\n",
    "    '''\n",
    "    \n",
    "    words = message\n",
    "    words = message.split(\" \")\n",
    "    words = [x.lower() for x in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(messages):\n",
    "    '''Create a dictionary mapping words to integer in dices\n",
    "    '''\n",
    "    \n",
    "    word_counts = collections.defaultdict(int)\n",
    "    \n",
    "    for message in messages:\n",
    "        for word in set(get_words(message)):\n",
    "            word_counts[word] += 1\n",
    "            \n",
    "    resulting_dictionary={}\n",
    "    \n",
    "    for word, count in word_counts.items():\n",
    "        if count>=25 and word not in stopwords.words('english') and len(word) >1:\n",
    "            next_index = len(resulting_dictionary)\n",
    "            resulting_dictionary[word] = next_index\n",
    "    \n",
    "    return resulting_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(messages, word_dictionary):\n",
    "    \"Transform a list of text messages into a numpy array for further processing.\"\n",
    "    \n",
    "    A = np.zeros((len(messages), len(word_dictionary)))\n",
    "    \n",
    "    for i, message in enumerate(messages):\n",
    "        for word in get_words(message):\n",
    "            if word in word_dictionary:\n",
    "                A[i, word_dictionary[word]] +=1\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "finalbooks['book_desc'] = finalbooks['book_desc'].fillna(finalbooks['title'])\n",
    "finalbooks['book_desc'] = finalbooks['book_desc'].str.replace(r'[^\\w\\s]',\"\")\n",
    "finalbooks['book_desc'] = finalbooks['book_desc'].fillna(finalbooks['tag_cloud'])\n",
    "finalbooks['tag_cloud'] = finalbooks['tag_cloud'].str.replace('-',\" \")\n",
    "finalbooks['words'] = finalbooks['book_desc'] +\" \"+finalbooks['tag_cloud']+\" \"+finalbooks['authors']\n",
    "dico = create_dictionary(finalbooks['book_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = transform_text(finalbooks['words'], dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.size(A, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(A, axis=1).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = np.sum((A>0), axis= 0)\n",
    "\n",
    "IDF = np.log(np.size(A, 0)/A1)\n",
    "IDF\n",
    "len(IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = A / (np.sum(A, axis=1, keepdims=True))\n",
    "np.shape(TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFiDF= TF*IDF\n",
    "np.shape(TFiDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFiDF = TFiDF / np.sqrt((np.sum(TFiDF**2, axis = 1, keepdims=True)+0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimC = np.dot(TFiDF, TFiDF.T)\n",
    "SimC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(SimC, axis = 1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(SimC, 1)\n",
    "SimC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookSim =pd.DataFrame(SimC, columns=finalbooks.title, index=finalbooks.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalbooks.title[np.argsort(SimC[15, :])[-6:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimC[15, [15, 2252, 6977, 4642, 2796, 1700 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalbooks [finalbooks.newbookid.isin(np.argsort(SimC[15, :])[-6:]+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "# Generate a custom diverging colormap followed by the correlation heatmap\n",
    "cmap =sns.diverging_palette(20, 220, n=20000)\n",
    "\n",
    "sns.heatmap(BookSim, cmap=cmap,center = 0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds = []\n",
    "train = train.sort_values(by=['newbookid'])\n",
    "for i in range(15000):\n",
    "  bi = train.newbookid[train.newuser_id == i+1]-1\n",
    "  Simi = SimC[:, bi]\n",
    "  ri = np.array(train[train.newuser_id == i+1].sort_values(by=['newbookid']).rating)\n",
    "  predi = finalbooks.filter(['newbookid'])\n",
    "  predi['pred'] = np.sum(Simi*ri, axis=1)/(np.sum(Simi, axis=1)+0.01)\n",
    "  predi['newuser_id'] = i+1\n",
    "  allpreds.append(predi)\n",
    "  if (i+1)%1000 == 0:\n",
    "        print(\"done: \", i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.concatenate(allpreds, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =pd.DataFrame(predictions, columns=['newbookid', 'pred', 'newuser_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['conc']=train['newuser_id'].map(str)+train['newbookid'].map(str)\n",
    "final['conc']=final['newuser_id'].map(str)+final['newbookid'].map(str)\n",
    "finalfin = final[~final.conc.isin(train.conc)]\n",
    "finalfin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalrank = test.merge(final,on = ['newbookid', 'newuser_id'])\n",
    "finalrank = finalrank.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
    "finalrank.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finallist = []\n",
    "for i in range(15000):\n",
    "    a = finalrank.loc[finalrank.newuser_id == i+1]['rating'].tolist()\n",
    "    finallist.append(a)\n",
    "    if (i+1)%1000 == 0:\n",
    "        print(\"done: \", i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([ndcg_k(r, len(r)) for r in finallist])\n",
    "\n",
    "facet, axes = plt.subplots(1, 1, figsize=(10, 3))\n",
    "n, bins, patches = plt.hist(b, 200, facecolor='blue', alpha=0.5) #, log = True)   \n",
    "plt.title('Distribution of NDGC among Users for the TFiDF model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = b[b == 1]\n",
    "sum(d)/15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = finalfin.sort_values('pred',ascending = False).groupby('newuser_id').head(10)\n",
    "top50 = finalfin.sort_values('pred',ascending = False).groupby('newuser_id').head(50)\n",
    "\n",
    "print('(1) TF-iDF Model RMSE: ', np.round(rmse(finalrank['pred'],finalrank['rating']), decimals=3))\n",
    "print('(2) TF-iDF Model NDCG: ', np.round(mean_ndcg(finallist), decimals=3))\n",
    "print(\"(3) Median NDCG: \", np.round(np.median(b), decimals=3))\n",
    "print(\"(4) Share of NDCG =1 among Users: \", np.round(sum(d)/15000, decimals=3))\n",
    "print('(5) TF-iDF Model Div10 Score: ',np.round(sum(np.in1d(top10.newbookid, tail.newbookid))/len(top10), decimals=3))\n",
    "print('(6) TF-iDF Model Div50 Score: ',np.round(sum(np.in1d(top50.newbookid, tail.newbookid))/len(top50), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalranktrain = train.merge(final,on = ['newbookid', 'newuser_id'])\n",
    "finalranktrain = finalranktrain.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
    "\n",
    "finalranktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finallisttrain = []\n",
    "for i in range(15000):\n",
    "    a = finalranktrain.loc[finalranktrain.newuser_id == i+1]['rating'].tolist()\n",
    "    finallisttrain.append(a)\n",
    "    if (i+1)%1000 == 0:\n",
    "        print(\"done: \", i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('(1) TF-iDF Train Model RMSE: ', np.round(rmse(finalranktrain['pred'],finalranktrain['rating']), decimals=3))\n",
    "print('(2) TF-iDF Train Model NDCG: ', np.round(mean_ndcg(finallisttrain), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
