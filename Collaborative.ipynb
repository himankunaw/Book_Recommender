{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalbooks = pd.read_csv('finalbook.csv')\n",
    "ratings = pd.read_csv('finalratings.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_k(r,k):\n",
    "    '''Discounted Cumulative Gain(DCG)\n",
    "    r: True Ratings in Predicted Rank Order(1st element is top recommendation)\n",
    "    k: Number of results to consider \n",
    "    '''\n",
    "    \n",
    "    r = np.asfarray(r)[:k]\n",
    "    dcg = np.sum(2**r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return dcg\n",
    "\n",
    "def ndcg_k(r,k):\n",
    "    \"Normalized Discounted Cumulative Gain(NDCG)\"\n",
    "    \n",
    "    dcg_max = dcg_k(sorted(r, reverse=True), k)\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return dcg_k(r,k) / dcg_max\n",
    "\n",
    "def mean_ndcg(rs):\n",
    "    '''Mean NDCG for all users\n",
    "    rs: Iterator/For each user: True ratings in Predicted Rank orde\n",
    "    '''\n",
    "    \n",
    "    mean = np.mean([ndcg_k(r, len(r)) for r in rs])\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y,h):\n",
    "    '''Root Mean Squared Error(RMSE)\n",
    "    y: real y\n",
    "    h: predicted y\n",
    "    '''\n",
    "    \n",
    "    a=y-h\n",
    "    return np.sqrt(sum(a**2)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATRIX FACTORIZATION\n",
    "def new_R(data, U, B):\n",
    "    nR = np.zeros(data.shape[0])\n",
    "    c = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        nR[c] = B[:, data.newbookid[i] - 1] @ U[data.newuser_id[i] - 1, :]\n",
    "\n",
    "        c += 1\n",
    "    return nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternate Least Square\n",
    "\n",
    "def ALS(train, k, lamu = 0.1, lamb = 0.1):\n",
    "    users = np.unique(train.newuser_id)\n",
    "    books = np.unique(train.newbookid)\n",
    "    nu = len(users)\n",
    "    nb = len(books)\n",
    "\n",
    "# Initialize U and B\n",
    "    U = np.ones((max(users), k)) / np.sqrt(k)\n",
    "    B = np.ones((k, max(books))) / np.sqrt(k)\n",
    "    \n",
    "    iter = 1\n",
    "    RMSE = 3\n",
    "    dRMSE = 1\n",
    "    rms = []\n",
    "    stop = 0.0001\n",
    "    max_iter = 24\n",
    "    \n",
    "    while (dRMSE > stop) and (iter < max_iter):\n",
    "      for i in users:\n",
    "        ind_B = train.newbookid[train.newuser_id == i] - 1\n",
    "        sub_B = B[:, ind_B]\n",
    "        nui = sub_B.shape[1]\n",
    "        Ai = sub_B @ np.transpose(sub_B) + lamu * np.identity(k)  \n",
    "        Vi = sub_B @ train.rating[train.newuser_id == i]\n",
    "        U[i - 1, :] = np.linalg.pinv(Ai) @ Vi\n",
    "        \n",
    "      nR = new_R(train, U, B)\n",
    "      new_RMSE = rmse(nR,train.rating)\n",
    "      dRMSEu = (RMSE - new_RMSE)\n",
    "      RMSE = new_RMSE.copy()\n",
    "      \n",
    "      rms.append(RMSE)\n",
    "      iter += 1\n",
    "      print(\"step: \", iter)\n",
    "\n",
    "      for i in books:\n",
    "        ind_U = train.newuser_id[train.newbookid == i] - 1\n",
    "        sub_U = U[ind_U, :]\n",
    "        nbi = sub_U.shape[0]\n",
    "        Ai = np.transpose(sub_U) @ sub_U + lamb * np.identity(k)  \n",
    "        Vi = np.transpose(sub_U) @ train.rating[train.newbookid == i]\n",
    "        B[:, i - 1] = np.linalg.pinv(Ai) @ Vi\n",
    "        \n",
    "      nR = new_R(train, U, B)\n",
    "      new_RMSE = rmse(nR,train.rating)\n",
    "      dRMSE = (RMSE - new_RMSE)\n",
    "      RMSE = new_RMSE.copy()\n",
    "      print(\"step: \", iter)\n",
    "      rms.append(RMSE)\n",
    "      iter += 1\n",
    "    w = {}\n",
    "    w['rms'] = rms\n",
    "    w['U'] = U\n",
    "    w['B'] = B\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traint, traincv = train_test_split(train,stratify=train['newuser_id'], test_size=0.20,random_state=42)\n",
    "traint = traint.reset_index(drop=True)\n",
    "traincv = traincv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = []\n",
    "trains = []\n",
    "cvs = []\n",
    "ndgs = []\n",
    "\n",
    "for k in [3]:\n",
    "  for alphau in  [ 0.125]:\n",
    "    for betab in  [0.075, 0.1, 0.2, 1]:\n",
    "      print(\"running for... alphau = \", alphau, \" and betab = \", betab)\n",
    "      w = ALS(traint, k, alphau, betab)\n",
    "      CVpred = new_R(traincv, w['U'], w['B'])\n",
    "      RMSE_CV = np.sqrt(np.mean((CVpred - traincv.rating) ** 2))\n",
    "      ranked = traincv.filter(['rating'])\n",
    "      ranked['pred'] = CVpred\n",
    "      ndgcv = ndcg_k(ranked.sort_values(by=['pred'], ascending = False).rating, len(ranked.sort_values(by=['pred'], ascending = False).rating))\n",
    "      ndgs.append(ndgcv)\n",
    "      ks.append(betab)\n",
    "      trains.append(w['rms'][-1])\n",
    "      cvs.append(RMSE_CV)\n",
    "      print(\"RMSEtrain: \", w['rms'][-1])\n",
    "      print(\"RMSECV: \", RMSE_CV)\n",
    "      print(\"done for: k= \", k, \"alphau= \", alphau, \"betab= \", betab)\n",
    "      print(\"RMSEtrain: \", w['rms'][-1])\n",
    "      print(\"RMSECV: \", RMSE_CV)\n",
    "      print(\"NDG: \", ndgcv)\n",
    "      print (\"w rms: \", w['rms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ks)\n",
    "print(trains)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ALS(train,  3, 0.1, 0.1)\n",
    "R = w['U'].dot(w['B'])\n",
    "rflat = np.matrix.flatten(R)\n",
    "testy = np.repeat(np.array(train.newuser_id.unique()), 8000)\n",
    "booky = np.tile(np.array(finalbooks.newbookid), 15000)\n",
    "booky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = np.sort(testy)\n",
    "testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(np.column_stack((testy, booky, rflat)), columns=('newuser_id','newbookid', 'pred'))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINING THE TAIL\n",
    "tailcomp = ratings.groupby(by= 'newbookid', as_index=False).agg({'rating':pd.Series.count}).sort_values(by = 'rating', ascending = False)\n",
    "tot = sum(tailcomp['rating'])\n",
    "tailcomp['popshare']= [x/tot for x in tailcomp['rating']]\n",
    "tailcomp['popshare']= tailcomp['popshare'].cumsum()\n",
    "tailcomp['category']= ['Head' if x<0.95 else \"Tail\" for x in tailcomp['popshare']]\n",
    "\n",
    "tail = tailcomp.loc[tailcomp.popshare >= 0.95]\n",
    "tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrank = test.merge(predictions,on = ['newbookid', 'newuser_id'])\n",
    "mfrank = mfrank.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
    "mfrank.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['conc']=train['newuser_id'].map(str)+train['newbookid'].map(str)\n",
    "pred['conc']=pred['newuser_id'].map(str)+pred['newbookid'].map(str)\n",
    "predfin = pred[~pred.conc.isin(train.conc)]\n",
    "predfin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflist = []\n",
    "for i in range(15000):\n",
    "    a = mfrank.loc[mfrank.newuser_id == i+1]['rating'].tolist()\n",
    "    mflist.append(a)\n",
    "mflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([ndcg_k(r, len(r)) for r in mflist])\n",
    "\n",
    "\n",
    "facet, axes = plt.subplots(1, 1, figsize=(10, 3))\n",
    "n, bins, patches = plt.hist(b, 200, facecolor='blue', alpha=0.5) #, log = True)   \n",
    "plt.title('Distribution of NDGC among Users for the MF model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = b[b == 1]\n",
    "sum(d)/15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = predictions.sort_values('pred',ascending = False).groupby('newuser_id').head(10)\n",
    "top50 = predictions.sort_values('pred',ascending = False).groupby('newuser_id').head(50)\n",
    "\n",
    "print('(1) MF Model RMSE: ', np.round(rmse(mfrank['pred'],mfrank['rating']), decimals=3))\n",
    "print('(2) MF Model NDCG: ', np.round(mean_ndcg(mflist), decimals=3))\n",
    "print(\"(3) Median NDCG: \", np.round(np.median(b), decimals=3))\n",
    "print(\"(4) Share of NDCG =1 among Users: \", np.round(sum(d)/15000, decimals=3))\n",
    "print('(5) MF Model Div10 Score: ',np.round(sum(np.in1d(top10.newbookid, tail.newbookid))/len(top10), decimals=3))\n",
    "print('(6) MF Model Div50 Score: ',np.round(sum(np.in1d(top50.newbookid, tail.newbookid))/len(top50), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfranktrain = train.merge(predictions,on = ['newbookid', 'newuser_id'])\n",
    "mfranktrain = mfranktrain.sort_values(by=['newuser_id', 'pred'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflisttrain = []\n",
    "for i in range(15000):\n",
    "    a = mfranktrain.loc[mfranktrain.newuser_id == i+1]['rating'].tolist()\n",
    "    mflisttrain.append(a)\n",
    "    \n",
    "mflisttrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('(1) MF Train Model RMSE: ', np.round(rmse(mfranktrain['pred'],mfranktrain['rating']), decimals=3))\n",
    "print('(2) MF Train Model NDCG: ', np.round(mean_ndcg(mflisttrain), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
